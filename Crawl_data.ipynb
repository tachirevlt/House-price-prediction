{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25f5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các danh sách lưu thuộc tính\n",
    "link_list = []\n",
    "dientich_list = []\n",
    "wc_list = []\n",
    "pn_list = []\n",
    "price_list = []\n",
    "huongnha_list = []\n",
    "huongbancong_list =[]\n",
    "mota= []\n",
    "time_list = []\n",
    "date_list = []\n",
    "Loai_list =[]\n",
    "quan_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ta sẽ cho Beautiful Soup duyệt qua lần lượt các Page (trang), mỗi trang sẽ lưu lại Link chi tiết của 20 sản phẩm được hiển thị\n",
    "# Do có tất cả 503 trang nên ta sẽ duyệt qua 503 trang để lấy tổng cộng 10 050 link sản phẩm\n",
    "\n",
    "# Lấy link đầu tiên từ mỗi phần tử 'div' với class 'item' trên các trang từ 1 đến 503\n",
    "for x in range(1, 504):\n",
    "    count = 0\n",
    "    link = f'https://batdongsan.vn/ban-nha-ho-chi-minh/p{x}'\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "\n",
    "    product_list = soup.find_all('div', class_='image cover')\n",
    "\n",
    "    for item in product_list:\n",
    "        for link in item.find_all('a', href=True):\n",
    "            link_list.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eba2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sau đó, ta sẽ mở từng link sản phẩm để trích xuất các thông tin bên trong sản phẩm\n",
    "\n",
    "for x in link_list:\n",
    "  # Mở từng link sản phẩm\n",
    "  response = requests.get(x)\n",
    "\n",
    "  # Kiểm tra nếu yêu cầu thành công\n",
    "  if response.status_code == 200:\n",
    "    # Biến để lưu trữ thông tin\n",
    "    dientich = None\n",
    "    wc = None\n",
    "    pn = None\n",
    "    price = None\n",
    "    huongnha = None\n",
    "    huongbancong = None\n",
    "    description = None\n",
    "    loai = None\n",
    "    quan = None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "    # -- Trích xuất\n",
    "    # Trích xuất giá\n",
    "    price = soup.find('strong', class_='price').text.strip()\n",
    "\n",
    "    # Trích xuất các giá trị: diện tích , số phòng ngủ , số phòng WC , Các hướng của nhà , Hướng ban công\n",
    "    ul_lists = soup.find_all('ul', class_='uk-list')\n",
    "    for ul in ul_lists:\n",
    "        li_elements = ul.find_all('li')\n",
    "        for li in li_elements:\n",
    "            text = li.text.strip()\n",
    "            if 'Diện tích:' in text:\n",
    "                dientich = text.split(':')[-1].strip()\n",
    "            elif 'Phòng WC:' in text:\n",
    "                wc = text.split(':')[-1].strip()\n",
    "            elif 'Phòng ngủ:' in text:\n",
    "                pn = text.split(':')[-1].strip()\n",
    "            elif 'Hướng nhà:' in text:\n",
    "                huongnha = text.split(':')[-1].strip()\n",
    "            elif 'Hướng ban công:' in text:\n",
    "                huongbancong = text.split(':')[-1].strip()\n",
    "\n",
    "    # Trích xuất mô tả\n",
    "    divs = soup.find_all('div', class_='content')\n",
    "\n",
    "    for div in divs:\n",
    "      if div.find('p'):\n",
    "        description = div.get_text(separator='\\n').strip()\n",
    "        break\n",
    "    mota.append(description)\n",
    "\n",
    "    # Trích xuất date and time\n",
    "    datetime = soup.find('time', class_='timeago').text\n",
    "    time, date = datetime.split()\n",
    "\n",
    "    # Trích xuất Quận, Loại nhà\n",
    "    links = soup.select('ul.uk-breadcrumb li a')\n",
    "\n",
    "    # Lấy văn bản của thẻ 'a' thứ hai\n",
    "    if len(links) > 1:\n",
    "      loai = links[1].text\n",
    "      quan = links[3].text\n",
    "\n",
    "    # Thêm các chuỗi tìm được vào List\n",
    "    dientich_list.append(dientich)\n",
    "    wc_list.append(wc)\n",
    "    pn_list.append(pn)\n",
    "    price_list.append(price)\n",
    "    huongnha_list.append(huongnha)\n",
    "    huongbancong_list.append(huongbancong)\n",
    "    time_list.append(time)\n",
    "    date_list.append(date)\n",
    "    Loai_list.append(loai)\n",
    "    quan_list.append(quan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo một DataFrame từ các List xây dựng được ở trên\n",
    "data_scraping = {\n",
    "    'Link' : link_list,\n",
    "    'Diện tich': dientich_list,\n",
    "    'Phòng WC': wc_list,\n",
    "    'Phòng ngủ': pn_list,\n",
    "    'Giá': price_list,\n",
    "    'Hướng nhà': huongnha_list,\n",
    "    'Hướng ban công': huongbancong_list,\n",
    "    'Mô tả ' : mota,\n",
    "    'Giờ đăng' : time_list,\n",
    "    'Ngày đăng ' : date_list,\n",
    "    'Quận' : quan_list,\n",
    "    'Loại nhà' : Loai_list\n",
    "}\n",
    "\n",
    "df_scraping = pd.DataFrame(data_scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98677920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển Dataframe thành File CSV để có thể sử dụng sau này\n",
    "df_scraping.to_csv('data_scraping.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
